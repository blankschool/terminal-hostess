from fastapi import (
    FastAPI,
    File,
    Form,
    HTTPException,
    Security,
    UploadFile,
    status,
    Query,
    Response,
)
from fastapi.security import APIKeyHeader
from fastapi.responses import FileResponse, RedirectResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from pydantic import BaseModel, HttpUrl
import subprocess
import shutil
import os
from pathlib import Path
from typing import Literal, Optional
import logging
from datetime import datetime
from dotenv import load_dotenv
import sys
from time import perf_counter
from urllib.parse import urlparse
from io import BytesIO
import tempfile
from starlette.background import BackgroundTask
from openai import OpenAI
import base64
import mimetypes
import re
import json
import asyncio
from concurrent.futures import ThreadPoolExecutor
import requests

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Diret√≥rios base
ROOT_DIR = Path(__file__).resolve().parent.parent
CONFIG_DIR = ROOT_DIR / "config"
COOKIES_DIR = CONFIG_DIR / "cookies"
FRONTEND_DIR = ROOT_DIR / "frontend"
FRONTEND_BUILD_DIR = FRONTEND_DIR / "dist"
# Use temporary directory for downloads (auto-cleanup)
DOWNLOADS_DIR = Path(tempfile.gettempdir()) / "n8n-download-bridge"

# Configura√ß√µes - Load .env BEFORE importing cobalt_config
load_dotenv(ROOT_DIR / ".env")
load_dotenv(CONFIG_DIR / ".env", override=False)

# Import Cobalt after environment variables are loaded
sys.path.insert(0, str(ROOT_DIR / "backend"))
from lib.cobalt_client import CobaltClient, CobaltAPIError, CobaltRateLimitError
from config import cobalt_config
DEFAULT_API_KEY = "cI4cA4Xvml2O0TCXdxRDuhHdY1251G34gso3VdHfDIc"
API_KEY = os.getenv("API_KEY", DEFAULT_API_KEY)
DEFAULT_TRANSCRIBE_PROMPT = (
    "Atue como um transcritor de documentos. Analise a imagem fornecida e "
    "transcreva todo o texto vis√≠vel exatamente como ele aparece."
)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_AUDIO_MODEL = os.getenv("OPENAI_AUDIO_MODEL", "whisper-1")
OPENAI_VISION_MODEL = os.getenv("OPENAI_VISION_MODEL", "gpt-4o-mini")

# Cookies
COOKIES_CANDIDATES = [
    COOKIES_DIR / "cookies.txt",
    ROOT_DIR / "cookies.txt",  # compatibilidade com estrutura antiga
]
PRIMARY_COOKIES_FILE = COOKIES_CANDIDATES[0]
DOMAIN_COOKIE_MAP: dict[str, list[Path]] = {
    "tiktok.com": [
        COOKIES_DIR / "www.tiktok.com_cookies.txt",
        ROOT_DIR / "www.tiktok.com_cookies.txt",
    ],
    "instagram.com": [
        COOKIES_DIR / "www.instagram.com_cookies.txt",
        ROOT_DIR / "www.instagram.com_cookies.txt",
    ],
}
ALT_COOKIES_FILES = [p for paths in DOMAIN_COOKIE_MAP.values() for p in paths]
_cookies_cache: dict[Path, tuple[float, Optional[list[str]]]] = {}


def get_cookies_args(url: Optional[str] = None) -> list[str]:
    """
    Retorna os argumentos de cookies para yt-dlp/gallery-dl
    Ignora arquivos vazios ou com formato inv√°lido para evitar erro 500.
    """
    candidates: list[Path] = []
    lower_host = ""
    if url:
        try:
            lower_host = urlparse(url).netloc.lower()
        except Exception:
            lower_host = url.lower()

    # Prioriza cookies espec√≠ficos por dom√≠nio quando houver
    for domain, cookie_paths in DOMAIN_COOKIE_MAP.items():
        if domain in lower_host:
            for cookie_path in cookie_paths:
                if cookie_path not in candidates:
                    candidates.append(cookie_path)

    # Fallbacks gen√©ricos (n√£o usa cookies de outros dom√≠nios)
    for p in COOKIES_CANDIDATES:
        if p not in candidates:
            candidates.append(p)

    for file_path in candidates:
        args = _cached_cookie_args(file_path)
        if args:
            return args
    return []


def _cached_cookie_args(file_path: Path) -> Optional[list[str]]:
    """L√™ cookies com cache por mtime para evitar I/O a cada requisi√ß√£o."""
    try:
        if not file_path.exists():
            _cookies_cache.pop(file_path, None)
            return None

        stat = file_path.stat()
        mtime = stat.st_mtime
        cached = _cookies_cache.get(file_path)
        if cached and cached[0] == mtime:
            return cached[1] or None

        if stat.st_size == 0:
            _cookies_cache[file_path] = (mtime, None)
            logger.info(f"{file_path.name} est√° vazio; ignorando.")
            return None

        with file_path.open("r", encoding="utf-8", errors="ignore") as f:
            head = f.read(200)
            if "HTTP Cookie File" not in head and "# Netscape" not in head:
                logger.warning(f"{file_path.name} n√£o parece Netscape; ignorando.")
                _cookies_cache[file_path] = (mtime, None)
                return None

        args = ["--cookies", str(file_path)]
        _cookies_cache[file_path] = (mtime, args)
        logger.info(f"Usando cookies de {file_path.name}")
        return args
    except Exception as exc:
        _cookies_cache.pop(file_path, None)
        logger.warning(f"N√£o foi poss√≠vel ler {file_path.name}, ignorando: {exc}")
        return None


_yt_dlp_path_cache: Optional[str] = None
_gallery_dl_path_cache: Optional[str] = None
_ffmpeg_path_cache: Optional[str] = None
_openai_client: Optional[OpenAI] = None
_cobalt_client: Optional[CobaltClient] = None


def _is_executable(path: Path) -> bool:
    return path.is_file() and os.access(path, os.X_OK)


def get_ffmpeg_location() -> Optional[str]:
    """
    Resolve o caminho do ffmpeg.
    Prioridade:
    1) FFMPEG_PATH (arquivo ou diret√≥rio)
    2) bin/ffmpeg dentro do projeto
    3) ffmpeg do PATH
    """
    global _ffmpeg_path_cache
    if _ffmpeg_path_cache is not None:
        return _ffmpeg_path_cache or None

    env_path = os.getenv("FFMPEG_PATH")
    if env_path:
        candidate = Path(env_path)
        if candidate.is_dir():
            ffmpeg_name = "ffmpeg.exe" if os.name == "nt" else "ffmpeg"
            dir_ffmpeg = candidate / ffmpeg_name
            if _is_executable(dir_ffmpeg):
                _ffmpeg_path_cache = str(candidate)
                logger.info(f"ffmpeg selecionado via FFMPEG_PATH (dir): {_ffmpeg_path_cache}")
                return _ffmpeg_path_cache
        if _is_executable(candidate):
            _ffmpeg_path_cache = str(candidate)
            logger.info(f"ffmpeg selecionado via FFMPEG_PATH: {_ffmpeg_path_cache}")
            return _ffmpeg_path_cache
        logger.warning(f"FFMPEG_PATH configurado, mas inv√°lido: {env_path}")

    local_bin = ROOT_DIR / "bin"
    ffmpeg_name = "ffmpeg.exe" if os.name == "nt" else "ffmpeg"
    local_ffmpeg = local_bin / ffmpeg_name
    if _is_executable(local_ffmpeg):
        _ffmpeg_path_cache = str(local_bin)
        logger.info(f"ffmpeg selecionado no projeto: {_ffmpeg_path_cache}")
        return _ffmpeg_path_cache

    system_ffmpeg = shutil.which("ffmpeg")
    if system_ffmpeg:
        _ffmpeg_path_cache = system_ffmpeg
        logger.info(f"ffmpeg encontrado no PATH: {_ffmpeg_path_cache}")
        return _ffmpeg_path_cache

    _ffmpeg_path_cache = ""
    logger.warning("ffmpeg n√£o encontrado; convers√µes podem falhar.")
    return None


def get_ffmpeg_location_arg() -> list[str]:
    location = get_ffmpeg_location()
    if location:
        return ["--ffmpeg-location", location]
    return []


def choose_yt_dlp_binary_for_url(url: str) -> str:
    """
    Para TikTok, usa ./bin/yt-dlp se dispon√≠vel (tem curl_cffi para impersonation).
    Para outras URLs, usa o bin√°rio do sistema (Homebrew/PATH).
    """
    lower = url.lower()
    if "tiktok.com" in lower:
        alt_bin = str(ROOT_DIR / "bin" / "yt-dlp")
        if _is_executable(Path(alt_bin)):
            return alt_bin
    return get_yt_dlp_binary()


def get_yt_dlp_binary() -> str:
    """
    Resolve bin√°rio do yt-dlp priorizando Homebrew/PATH.
    Ordem:
    1) YT_DLP_PATH (override expl√≠cito)
    2) yt-dlp do PATH (Homebrew)
    3) Bin√°rio do venv (pip)
    4) Repo local yt-dlp-master (download do GitHub) como fallback
    """
    global _yt_dlp_path_cache
    if _yt_dlp_path_cache:
        return _yt_dlp_path_cache

    env_path = os.getenv("YT_DLP_PATH")
    if env_path:
        env_candidate = Path(env_path)
        if _is_executable(env_candidate):
            _yt_dlp_path_cache = str(env_candidate)
            logger.info(f"yt-dlp selecionado via YT_DLP_PATH: {_yt_dlp_path_cache}")
            return _yt_dlp_path_cache
        logger.warning(f"YT_DLP_PATH configurado, mas n√£o execut√°vel: {env_path}")

    candidates: list[str] = []

    # Priorizar yt-dlp do PATH (Homebrew)
    path_bin = shutil.which("yt-dlp")
    if path_bin:
        candidates.append(path_bin)

    venv_bin = Path(sys.executable).parent / "yt-dlp"
    if _is_executable(venv_bin):
        candidates.append(str(venv_bin))

    local_repo = ROOT_DIR / "yt-dlp-master"
    for name in ("yt-dlp.sh", "yt-dlp"):
        candidate = local_repo / name
        if _is_executable(candidate):
            candidates.append(str(candidate))

    for path in candidates:
        _yt_dlp_path_cache = path
        logger.info(f"yt-dlp selecionado: {_yt_dlp_path_cache}")
        return _yt_dlp_path_cache

    _yt_dlp_path_cache = "yt-dlp"
    logger.info("yt-dlp selecionado: yt-dlp (PATH)")
    return _yt_dlp_path_cache


def get_gallery_dl_binary() -> str:
    """
    Resolve bin√°rio do gallery-dl priorizando a instala√ß√£o est√°vel (pip/venv).
    Ordem:
    1) GALLERY_DL_PATH (override expl√≠cito)
    2) Bin√°rio do venv (pip)
    3) gallery-dl do PATH
    4) Repo local gallery-dl-master/bin/gallery-dl como fallback
    """
    global _gallery_dl_path_cache
    if _gallery_dl_path_cache:
        return _gallery_dl_path_cache

    env_path = os.getenv("GALLERY_DL_PATH")
    if env_path:
        env_candidate = Path(env_path)
        if _is_executable(env_candidate):
            _gallery_dl_path_cache = str(env_candidate)
            logger.info(f"gallery-dl selecionado via GALLERY_DL_PATH: {_gallery_dl_path_cache}")
            return _gallery_dl_path_cache
        logger.warning(f"GALLERY_DL_PATH configurado, mas n√£o execut√°vel: {env_path}")

    candidates: list[str] = []

    venv_bin = Path(sys.executable).parent / "gallery-dl"
    if _is_executable(venv_bin):
        candidates.append(str(venv_bin))

    path_bin = shutil.which("gallery-dl")
    if path_bin:
        candidates.append(path_bin)

    local_repo = ROOT_DIR / "gallery-dl-master"
    for name in ("bin/gallery-dl", "gallery-dl"):
        candidate = local_repo / name
        if _is_executable(candidate):
            candidates.append(str(candidate))

    for path in candidates:
        _gallery_dl_path_cache = path
        logger.info(f"gallery-dl selecionado: {_gallery_dl_path_cache}")
        return _gallery_dl_path_cache

    _gallery_dl_path_cache = "gallery-dl"
    logger.info("gallery-dl selecionado: gallery-dl (PATH)")
    return _gallery_dl_path_cache


def download_tiktok_audio_via_tikwm(url: str, output_dir: Path, audio_format: str = "mp3") -> Path:
    """
    Baixa v√≠deo TikTok via tikwm.com e extrai o √°udio usando ffmpeg.
    Retorna o caminho do arquivo de √°udio.
    Optimized with reduced timeouts.
    """
    logger.info(f"üéµ Baixando TikTok e extraindo √°udio via tikwm.com: {url}")

    try:
        # Primeiro, baixar o v√≠deo via tikwm
        video_result = download_tiktok_via_tikwm(url, output_dir)
        video_path = Path(video_result["file_path"])

        # Gerar nome do arquivo de √°udio
        audio_filename = video_path.stem + f".{audio_format}"
        audio_path = output_dir / audio_filename

        # Extrair √°udio usando ffmpeg
        ffmpeg_bin = resolve_ffmpeg_binary()
        cmd = [
            ffmpeg_bin,
            "-i", str(video_path),
            "-vn",  # sem v√≠deo
            "-acodec", "libmp3lame" if audio_format == "mp3" else "copy",
            "-y",  # sobrescrever
            str(audio_path)
        ]

        logger.info(f"Extraindo √°udio com ffmpeg: {' '.join(cmd)}")
        subprocess.run(cmd, capture_output=True, text=True, timeout=60, check=True)  # Reduced from 120s to 60s

        # Remover arquivo de v√≠deo tempor√°rio
        video_path.unlink(missing_ok=True)
        logger.info(f"‚úÖ √Åudio extra√≠do com sucesso via tikwm.com: {audio_path}")

        return audio_path

    except subprocess.CalledProcessError as e:
        logger.error(f"Erro ao extrair √°udio com ffmpeg: {e.stderr}")
        raise Exception(f"Falha ao extrair √°udio: {str(e)}")
    except Exception as e:
        logger.error(f"Erro ao baixar TikTok e extrair √°udio: {e}")
        raise


def download_tiktok_via_tikwm(url: str, output_dir: Path) -> dict:
    """
    Download de TikTok usando a API gratuita do tikwm.com.
    OPTIMIZED for maximum speed: reduced timeouts, larger chunks, connection reuse.
    """
    from time import perf_counter
    t0 = perf_counter()
    
    # Use session for connection reuse (faster)
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        "Connection": "keep-alive",
        "Accept": "*/*",
        "Accept-Encoding": "gzip, deflate",
    })

    try:
        # Fast API call with reduced timeout
        api_url = f"https://www.tikwm.com/api/?url={url}"
        t1 = perf_counter()
        resp = session.get(api_url, timeout=8, verify=False)  # Faster: 8s timeout, skip SSL verification
        resp.raise_for_status()
        data = resp.json()
        t2 = perf_counter()
        logger.info(f"‚ö° tikwm API responded in {(t2-t1)*1000:.0f}ms")

        if data.get("code") != 0:
            raise Exception(f"API tikwm retornou erro: {data.get('msg', 'Unknown error')}")

        video_data = data.get("data", {})

        # Get video URL (prefer no watermark)
        video_url = video_data.get("play") or video_data.get("wmplay")
        if not video_url:
            raise Exception("Nenhuma URL de v√≠deo encontrada na resposta do tikwm")

        # Generate filename
        video_id = video_data.get("id", "tiktok")
        author = video_data.get("author", {}).get("unique_id", "unknown")
        filename = f"tiktok_{author}_{video_id}.mp4"
        file_path = output_dir / filename

        # Fast video download with larger chunks
        t3 = perf_counter()
        video_resp = session.get(video_url, timeout=30, stream=True, verify=False)
        video_resp.raise_for_status()

        # Use 64KB chunks for faster I/O
        with open(file_path, "wb") as f:
            for chunk in video_resp.iter_content(chunk_size=65536):  # 64KB chunks
                if chunk:
                    f.write(chunk)

        t4 = perf_counter()
        file_size = file_path.stat().st_size
        size_mb = file_size / (1024 * 1024)
        total_time = t4 - t0
        speed_mbps = (size_mb * 8) / total_time if total_time > 0 else 0
        logger.info(f"‚ö° TikTok downloaded: {size_mb:.2f}MB in {total_time:.2f}s ({speed_mbps:.1f} Mbps)")

        return {
            "success": True,
            "file_path": str(file_path),
            "file_size": get_file_size(file_path),
            "format": "mp4",
            "title": video_data.get("title", ""),
            "author": author,
            "source": "tikwm"
        }

    except requests.exceptions.RequestException as e:
        logger.error(f"Erro de rede ao usar tikwm: {e}")
        raise Exception(f"Falha na API tikwm: {str(e)}")
    except Exception as e:
        logger.error(f"Erro ao usar tikwm: {e}")
        raise


def get_impersonate_args(url: str) -> list[str]:
    """
    Retorna args de impersonation para TikTok (Chrome-120).
    Se n√£o for TikTok, retorna vazio.
    """
    lowered = url.lower()
    if "tiktok.com" not in lowered:
        return []
    return ["--impersonate", "Chrome-120"]


_impersonation_cache_by_path: dict[str, bool] = {}


def get_openai_client() -> OpenAI:
    """Retorna cliente OpenAI com cache."""
    global _openai_client
    if _openai_client:
        return _openai_client
    if not OPENAI_API_KEY:
        raise HTTPException(status_code=500, detail="OPENAI_API_KEY n√£o configurada")
    _openai_client = OpenAI(api_key=OPENAI_API_KEY)
    return _openai_client


def get_cobalt_client() -> CobaltClient:
    """Retorna cliente Cobalt com cache."""
    global _cobalt_client
    if _cobalt_client:
        return _cobalt_client
    
    api_url = cobalt_config.get_cobalt_url()
    api_key = cobalt_config.COBALT_API_KEY
    timeout = cobalt_config.COBALT_TIMEOUT
    
    _cobalt_client = CobaltClient(
        api_url=api_url,
        api_key=api_key,
        timeout=timeout
    )
    logger.info(f"Cobalt client initialized: {api_url}")
    return _cobalt_client


def download_via_cobalt(url: str, audio_only: bool = False, quality: str = "max") -> dict:
    """
    Download media using Cobalt API.
    Returns dict with:
        - blob: bytes of the downloaded file
        - filename: suggested filename
        - content_type: MIME type
    """
    t0 = perf_counter()
    client = get_cobalt_client()
    platform = detectPlatform(url)  # Detect platform early for use throughout function
    
    try:
        logger.info(f"Downloading via Cobalt: {url} (audio_only={audio_only}, quality={quality})")
        
        # Get download info from Cobalt
        result = client.download(
            url=url,
            quality=quality,
            audio_only=audio_only,
            audio_format="mp3" if audio_only else "best",
        )
        
        status = result.get("status")
        t1 = perf_counter()
        logger.info(f"Cobalt response received in {(t1 - t0) * 1000:.0f}ms, status={status}")
        
        # Handle different response types
        download_url = None
        
        if status == "redirect" or status == "stream" or status == "tunnel":
            download_url = result.get("url")
        elif status == "picker":
            # Multiple options (e.g., Twitter with multiple videos)
            urls = result.get("picker", [])
            if urls:
                download_url = urls[0].get("url")
        
        if not download_url:
            raise HTTPException(
                status_code=500,
                detail=f"Cobalt returned unexpected status: {status}"
            )
        
        # Download the actual file with optimized settings
        t2 = perf_counter()
        # Use session for connection pooling and keep-alive
        download_session = requests.Session()
        download_session.headers.update({
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
            "Accept": "*/*",
            "Accept-Encoding": "gzip, deflate",
            "Connection": "keep-alive",
            "Referer": url,
        })
        response = download_session.get(
            download_url, 
            timeout=30,  # Reduced timeout for faster failure
            stream=True,
            allow_redirects=True,
            verify=False,  # Skip SSL verification for speed
        )
        response.raise_for_status()
        
        # Get filename from Content-Disposition
        filename = None
        content_disposition = response.headers.get("Content-Disposition", "")
        if "filename=" in content_disposition:
            filename = content_disposition.split("filename=")[-1].strip('"')
        
        # Fallback filename
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            ext = "mp3" if audio_only else "mp4"
            content_type = response.headers.get("Content-Type", "")
            if "webm" in content_type:
                ext = "webm"
            filename = f"{platform}_{timestamp}.{ext}"
        
        # Check Content-Length header before downloading
        content_length = response.headers.get("Content-Length")
        if content_length:
            try:
                expected_size = int(content_length)
                if expected_size == 0:
                    logger.error(f"‚ùå Content-Length is 0 for {url} (platform: {platform})")
                    if cobalt_config.ENABLE_YTDLP_FALLBACK:
                        logger.info("üîÑ Falling back to yt-dlp due to zero Content-Length")
                        return download_via_ytdlp_fallback(url, audio_only)
                    raise HTTPException(status_code=500, detail="Download failed: Content-Length is 0")
            except ValueError:
                pass  # Invalid Content-Length, continue with download
        
        # Read the file content with larger chunks for speed
        content = b""
        for chunk in response.iter_content(chunk_size=65536):  # 64KB chunks for faster I/O
            if chunk:
                content += chunk
        
        t3 = perf_counter()
        size_mb = len(content) / (1024 * 1024)
        
        # Validate that content is not empty
        if len(content) == 0:
            logger.error(f"‚ùå Empty content received from Cobalt for {url} (platform: {platform}, status: {status})")
            logger.error(f"   Download URL: {download_url[:200]}...")
            logger.error(f"   Response headers: {dict(response.headers)}")
            if cobalt_config.ENABLE_YTDLP_FALLBACK:
                logger.info("üîÑ Falling back to yt-dlp due to empty content")
                return download_via_ytdlp_fallback(url, audio_only)
            raise HTTPException(status_code=500, detail="Download failed: empty content from Cobalt")
        
        logger.info(f"‚úÖ Downloaded {size_mb:.2f}MB via Cobalt in {(t3 - t2) * 1000:.0f}ms")
        logger.info(f"üèÅ Total Cobalt download time for {platform}: {(t3 - t0) * 1000:.0f}ms")
        
        content_type = response.headers.get("Content-Type", "application/octet-stream")
        
        return {
            "blob": content,
            "filename": filename,
            "content_type": content_type,
            "size": len(content)
        }
        
    except CobaltRateLimitError as e:
        logger.error(f"Cobalt rate limit: {e}")
        raise HTTPException(
            status_code=429,
            detail="Rate limit excedido. Tente novamente em alguns minutos."
        )
    
    except CobaltAPIError as e:
        error_msg = str(e)
        logger.error(f"‚ùå Cobalt API error: {error_msg}")
        
        # Check if it's a TikTok-specific error (platform already defined at function start)
        is_tiktok = platform == "tiktok"
        is_tiktok_error = "tiktok" in error_msg.lower() or "fetch.fail" in error_msg.lower()
        
        if is_tiktok or is_tiktok_error:
            logger.warning(f"‚ö†Ô∏è  TikTok detected with Cobalt failure - using optimized fallback")
            if cobalt_config.ENABLE_YTDLP_FALLBACK:
                logger.info("üîÑ Falling back to yt-dlp for TikTok...")
                return download_via_ytdlp_fallback(url, audio_only)
        
        # Check if it's the API shutdown error
        if "shut down" in error_msg.lower() or "v7" in error_msg.lower():
            logger.warning("Cobalt API unavailable - using yt-dlp fallback")
            if cobalt_config.ENABLE_YTDLP_FALLBACK:
                logger.info("Usando yt-dlp como fallback...")
                return download_via_ytdlp_fallback(url, audio_only)
            else:
                raise HTTPException(
                    status_code=503,
                    detail="Cobalt API indispon√≠vel. Considere usar uma inst√¢ncia auto-hospedada do Cobalt ou habilitar o fallback para yt-dlp."
                )
        
        # Optional fallback to yt-dlp for other errors
        if cobalt_config.ENABLE_YTDLP_FALLBACK:
            logger.info("üîÑ Tentando fallback para yt-dlp...")
            # Use the old method as fallback
            return download_via_ytdlp_fallback(url, audio_only)
        
        raise HTTPException(
            status_code=503,
            detail=f"Erro ao baixar via Cobalt: {str(e)}. Considere usar uma inst√¢ncia auto-hospedada."
        )
    
    except Exception as e:
        logger.error(f"Unexpected error in Cobalt download: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro inesperado: {str(e)}"
        )


def detectPlatform(url: str) -> str:
    """Helper function to detect platform from URL"""
    lower_url = url.lower()
    if "youtube.com" in lower_url or "youtu.be" in lower_url or "music.youtube.com" in lower_url:
        return "youtube"
    if "tiktok.com" in lower_url:
        return "tiktok"
    if "instagram.com" in lower_url:
        return "instagram"
    if "twitter.com" in lower_url or "x.com" in lower_url:
        return "twitter"
    if "reddit.com" in lower_url or "redd.it" in lower_url:
        return "reddit"
    if "pinterest.com" in lower_url or "pin.it" in lower_url:
        return "pinterest"
    if "twitch.tv" in lower_url:
        return "twitch"
    if "vimeo.com" in lower_url:
        return "vimeo"
    if "soundcloud.com" in lower_url:
        return "soundcloud"
    if "bilibili.com" in lower_url or "bilibili.tv" in lower_url:
        return "bilibili"
    if "tumblr.com" in lower_url:
        return "tumblr"
    if "dailymotion.com" in lower_url:
        return "dailymotion"
    if "streamable.com" in lower_url:
        return "streamable"
    if "facebook.com" in lower_url or "fb.watch" in lower_url:
        return "facebook"
    if "snapchat.com" in lower_url:
        return "snapchat"
    if "loom.com" in lower_url:
        return "loom"
    return "other"


def download_via_ytdlp_fallback(url: str, audio_only: bool = False) -> dict:
    """
    Fallback to yt-dlp if Cobalt fails.
    OPTIMIZED for maximum download speed while maintaining max quality.
    Uses aria2c multi-threading when available.
    """
    from time import perf_counter
    t_start = perf_counter()
    platform = detectPlatform(url)
    logger.info(f"‚ö° Using OPTIMIZED yt-dlp fallback for {platform}: {url}")
    
    # Use the existing yt-dlp infrastructure
    if audio_only:
        # Use audio extraction
        audio_path = download_audio_from_url(url, "mp3")
        with open(audio_path, "rb") as f:
            content = f.read()
        audio_path.unlink(missing_ok=True)
        
        t_end = perf_counter()
        logger.info(f"‚úÖ Audio downloaded via yt-dlp fallback for {platform} in {(t_end - t_start) * 1000:.0f}ms")
        
        return {
            "blob": content,
            "filename": audio_path.name,
            "content_type": "audio/mpeg",
            "size": len(content)
        }
    else:
        # Use video download with optimizations
        result = execute_ytdlp_optimized(url, output_format="mp4")
        file_path = Path(result["file_path"])
        
        with open(file_path, "rb") as f:
            content = f.read()
        
        filename = file_path.name
        file_path.unlink(missing_ok=True)
        
        t_end = perf_counter()
        size_mb = len(content) / (1024 * 1024)
        speed_mbps = (size_mb * 8) / ((t_end - t_start) or 1)  # Avoid division by zero
        logger.info(f"‚úÖ Video downloaded via yt-dlp fallback for {platform}: {size_mb:.2f}MB in {(t_end - t_start):.1f}s ({speed_mbps:.1f} Mbps)")
        
        return {
            "blob": content,
            "filename": filename,
            "content_type": "video/mp4",
            "size": len(content)
        }


def sanitize_filename(filename: str, max_length: int = 200) -> str:
    """
    Sanitize filename to be filesystem-safe and limit length.
    Removes invalid characters and truncates if too long.
    """
    # Remove invalid characters for filenames
    invalid_chars = '<>:"/\\|?*'
    for char in invalid_chars:
        filename = filename.replace(char, '_')
    
    # Remove leading/trailing spaces and dots
    filename = filename.strip('. ')
    
    # Truncate if too long (leave room for extension)
    if len(filename) > max_length:
        filename = filename[:max_length]
    
    # If empty after sanitization, use fallback
    if not filename:
        filename = "video"
    
    return filename


def extract_username_from_instagram_url(original_url: str) -> str:
    """
    Extract Instagram username from URL.
    Tries to find username in URL patterns, returns sanitized name or fallback.
    
    Examples:
        https://www.instagram.com/username/reel/ID ‚Üí username
        https://www.instagram.com/reel/ID ‚Üí instagram (fallback)
        https://www.instagram.com/p/ID ‚Üí instagram (fallback)
    """
    # Pattern: /username/content_type/ID
    # Match format like: instagram.com/USERNAME/(reel|p|stories)/...
    match = re.search(r'instagram\.com/([^/]+)/(reel|p|stories|tv)/', original_url)
    if match:
        username = match.group(1)
        # Exclude reserved paths that aren't usernames
        if username not in ['reel', 'p', 'stories', 'tv', 'explore', 'accounts']:
            return sanitize_filename(username, max_length=50)
    
    # Try alternative pattern: /username/ at the end or followed by query params
    match = re.search(r'instagram\.com/([^/?#]+)/?(?:\?|#|$)', original_url)
    if match:
        username = match.group(1)
        if username not in ['reel', 'p', 'stories', 'tv', 'explore', 'accounts']:
            return sanitize_filename(username, max_length=50)
    
    # Fallback
    return "instagram"


def execute_ytdlp_optimized(url: str, output_format: str = "mp4") -> dict:
    """
    yt-dlp execution with BEST QUALITY (no aggressive optimizations).
    Simple and reliable download with best available formats.
    Uses uploader name or video title as filename.
    """
    t0 = perf_counter()
    platform = detectPlatform(url)
    
    # Use meaningful filenames: uploader name or video title
    # YouTube: %(title)s gives the video title
    # Instagram: %(uploader)s gives the account name
    # TikTok: %(uploader)s gives the username
    if platform == "youtube":
        # For YouTube, use video title as filename
        output_template = str(DOWNLOADS_DIR / "%(title)s.%(ext)s")
    else:
        # For other platforms, use uploader/username
        output_template = str(DOWNLOADS_DIR / "%(uploader)s_%(id)s.%(ext)s")
    
    cmd = [choose_yt_dlp_binary_for_url(url)]
    cmd.extend(get_cookies_args(url))
    cmd.extend(get_impersonate_args(url))
    cmd.extend(get_ffmpeg_location_arg())
    
    # UNIVERSAL COMPATIBILITY DOWNLOAD
    cmd.extend([
        # Format selection: Prioritize H.264 video + AAC audio for universal playback
        # This ensures the video plays on ALL devices/players without conversion
        # Priority order:
        #   1. MP4 with H.264 (avc1) video + M4A audio
        #   2. Any MP4 video + M4A audio
        #   3. Best MP4 available
        #   4. Best format available (fallback)
        '-f', 'bestvideo[ext=mp4][vcodec^=avc1]+bestaudio[ext=m4a]/bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',
        
        # Post-processing: Re-encode if needed to ensure H.264 + AAC
        # This guarantees compatibility even if source format is VP9/AV1/OPUS
        '--postprocessor-args', 'ffmpeg:-c:v libx264 -c:a aac',
        '--recode-video', 'mp4',
        
        # Merge to MP4 container
        '--merge-output-format', 'mp4',
        
        # Basic settings
        '--no-check-certificate',
        '--no-playlist',
        
        # Restrict filename length and sanitize
        '--restrict-filenames',  # ASCII-only filenames
        '--trim-filenames', '200',  # Limit filename length
        
        # Output
        '-o', output_template,
        '--progress',
        '--newline',
    ])
    
    cmd.append(url)
    logger.info(f"‚ö° Executing optimized yt-dlp: {' '.join(cmd[:10])}...")
    
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=600,  # 10 minute timeout for large files
        )
        
        t1 = perf_counter()
        
        if result.returncode != 0:
            logger.error(f"yt-dlp error: {result.stderr}")
            raise Exception(f"yt-dlp failed: {result.stderr[:500]}")
        
        # Find the downloaded file (search by pattern since filename is dynamic)
        downloaded_files = sorted(
            DOWNLOADS_DIR.glob("*.mp4"),
            key=lambda p: p.stat().st_mtime,
            reverse=True
        )
        
        if not downloaded_files:
            raise Exception("No file downloaded")
        
        # Get the most recently modified file (the one we just downloaded)
        file_path = downloaded_files[0]
        file_size = file_path.stat().st_size
        size_mb = file_size / (1024 * 1024)
        download_time = t1 - t0
        speed_mbps = (size_mb * 8) / (download_time or 1)
        
        logger.info(f"‚ö° Optimized download complete: {size_mb:.1f}MB in {download_time:.1f}s ({speed_mbps:.1f} Mbps)")
        logger.info(f"üìÅ Filename: {file_path.name}")
        
        return {
            "success": True,
            "file_path": str(file_path),
            "file_size": get_file_size(file_path),
            "format": file_path.suffix.lstrip('.'),
            "download_time": download_time,
            "speed_mbps": speed_mbps,
        }
        
    except subprocess.TimeoutExpired:
        logger.error("yt-dlp timed out after 600s")
        raise Exception("Download timed out")
    except Exception as e:
        logger.error(f"Optimized yt-dlp error: {e}")
        raise


def resolve_ffmpeg_binary() -> str:
    """Resolve o bin√°rio do ffmpeg para chamadas diretas."""
    location = get_ffmpeg_location()
    if location and Path(location).is_dir():
        name = "ffmpeg.exe" if os.name == "nt" else "ffmpeg"
        return str(Path(location) / name)
    return location or "ffmpeg"


def download_audio_from_url(url: str, audio_format: str = "mp3") -> Path:
    """Baixa apenas o √°udio usando yt-dlp e retorna o caminho do arquivo."""

    # Para TikTok, tentar tikwm.com primeiro, mas fallback para yt-dlp se falhar
    if "tiktok" in url.lower():
        try:
            logger.info("TikTok detectado - tentando API tikwm.com para √°udio")
            return download_tiktok_audio_via_tikwm(url, DOWNLOADS_DIR, audio_format)
        except Exception as e:
            logger.warning(f"tikwm.com √°udio falhou: {e}. Usando yt-dlp como fallback.")

    t0 = perf_counter()
    platform = detectPlatform(url)
    
    # Use meaningful filenames based on platform
    if platform == "youtube":
        output_template = str(DOWNLOADS_DIR / "%(title)s.%(ext)s")
    else:
        output_template = str(DOWNLOADS_DIR / "%(uploader)s_%(id)s.%(ext)s")

    # Detectar YouTube para otimiza√ß√µes
    lower_url = url.lower()
    is_youtube = "youtube.com" in lower_url or "youtu.be" in lower_url

    cmd: list[str] = [choose_yt_dlp_binary_for_url(url)]
    cmd.extend(get_cookies_args(url))
    cmd.extend(get_impersonate_args(url))
    cmd.extend(get_ffmpeg_location_arg())

    # Adicionar otimiza√ß√µes do YouTube antes da extra√ß√£o de √°udio
    if is_youtube:
        cmd.extend([
            '--extractor-args', 'youtube:player_client=android',  # Emular cliente Android
            '--http-chunk-size', '10M',  # Chunks de 10MB
        ])
        # Verificar se aria2c est√° dispon√≠vel para multi-threading
        if shutil.which("aria2c"):
            cmd.extend([
                '--external-downloader', 'aria2c',
                '--external-downloader-args', '-x 16 -s 16 -k 1M',  # 16 conex√µes paralelas
            ])
            logger.info("YouTube √°udio: Usando aria2c com 16 conex√µes paralelas")

    cmd.extend([
        "-x",
        "--audio-format",
        audio_format,
        "-o",
        output_template,
        "--no-playlist",
        "--restrict-filenames",  # ASCII-only filenames
        "--trim-filenames", "200",  # Limit filename length
        "--progress",
        "--newline"
    ])
    cmd.append(url)

    logger.info(f"Baixando √°udio com yt-dlp: {' '.join(cmd)}")
    try:
        t1 = perf_counter()
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300,
            check=True
        )
        t2 = perf_counter()

        # Find the most recently downloaded audio file
        audio_extensions = [f"*.{audio_format}", "*.m4a", "*.mp3", "*.opus", "*.ogg"]
        downloaded_files = []
        for ext in audio_extensions:
            downloaded_files.extend(DOWNLOADS_DIR.glob(ext))
        
        if not downloaded_files:
            raise Exception("√Åudio n√£o encontrado ap√≥s download")
        
        # Get the most recently modified file
        downloaded_files = sorted(downloaded_files, key=lambda p: p.stat().st_mtime, reverse=True)

        file_path = downloaded_files[0]
        logger.info(
            "yt-dlp √°udio timing prep=%.1fms run=%.1fms",
            (t1 - t0) * 1000,
            (t2 - t1) * 1000,
        )
        logger.debug(result.stdout)
        return file_path
    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=408, detail="Download de √°udio timeout (5 minutos)")
    except subprocess.CalledProcessError as exc:
        logger.error(f"Erro ao baixar √°udio: {exc.stderr}")
        error_msg = exc.stderr or str(exc)

        # Provide more user-friendly error messages
        if "Unable to extract" in error_msg or "Unable to download" in error_msg or "IP address is blocked" in error_msg or "Video not available" in error_msg:
            raise HTTPException(
                status_code=503,
                detail="Falha ao extrair v√≠deo. O site pode ter mudado ou bloqueado o acesso."
            )
        else:
            raise HTTPException(status_code=500, detail=f"Erro no download: {error_msg[:200]}")
    except Exception as exc:
        raise HTTPException(status_code=500, detail=str(exc))


def extract_audio_from_upload(upload_path: Path, audio_format: str = "mp3") -> Path:
    """Extrai √°udio de um arquivo local usando ffmpeg."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = DOWNLOADS_DIR / f"audio_extract_{timestamp}.{audio_format}"
    ffmpeg_bin = resolve_ffmpeg_binary()

    codec_args = {
        "mp3": ["-acodec", "libmp3lame"],
        "m4a": ["-acodec", "aac"],
        "wav": ["-acodec", "pcm_s16le", "-ar", "16000"],
    }.get(audio_format, ["-acodec", "libmp3lame"])

    cmd = [
        ffmpeg_bin,
        "-y",
        "-i",
        str(upload_path),
        "-vn",
        *codec_args,
        str(output_path),
    ]

    logger.info(f"Extraindo √°udio via ffmpeg: {' '.join(cmd)}")
    try:
        subprocess.run(cmd, capture_output=True, text=True, timeout=240, check=True)
        if not output_path.exists():
            raise Exception("Arquivo de √°udio n√£o gerado")
        return output_path
    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=408, detail="Extra√ß√£o de √°udio timeout (4 minutos)")
    except subprocess.CalledProcessError as exc:
        logger.error(f"Erro no ffmpeg: {exc.stderr}")
        raise HTTPException(status_code=500, detail="Falha ao extrair √°udio")


def transcribe_audio_file(audio_path: Path, language: Optional[str] = None) -> str:
    """Transcreve √°udio com Whisper."""
    try:
        with audio_path.open("rb") as f:
            result = get_openai_client().audio.transcriptions.create(
                model=OPENAI_AUDIO_MODEL,
                file=f,
                language=language,
                response_format="text"
            )
        if isinstance(result, str):
            return result
        text = getattr(result, "text", None)
        return text or str(result)
    except HTTPException:
        raise
    except Exception as exc:
        logger.error(f"Erro ao transcrever √°udio: {exc}")
        raise HTTPException(status_code=500, detail="Falha na transcri√ß√£o de √°udio")


def transcribe_image_bytes(data: bytes, mime_type: str = "image/png", prompt: Optional[str] = None) -> str:
    """Transcreve texto de uma imagem usando modelo vision."""
    effective_prompt = prompt or DEFAULT_TRANSCRIBE_PROMPT
    try:
        b64 = base64.b64encode(data).decode()
        res = get_openai_client().chat.completions.create(
            model=OPENAI_VISION_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "Extraia todo o texto vis√≠vel da imagem e retorne somente o texto."
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": effective_prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime_type};base64,{b64}"
                            }
                        }
                    ]
                }
            ],
            temperature=0,
            max_tokens=800
        )
        return res.choices[0].message.content.strip()
    except HTTPException:
        raise
    except Exception as exc:
        logger.error(f"Erro ao transcrever imagem: {exc}")
        raise HTTPException(status_code=500, detail="Falha na transcri√ß√£o de imagem")


def clean_instagram_filename(url: str, username: str, index: int) -> str:
    """
    Gera filename limpo para imagens do Instagram a partir da URL do CDN.
    Remove query parameters e gera nome descritivo.
    
    Exemplos:
        https://.../.../image.jpg?param=value -> instagram_username_01.jpg
    """
    try:
        # Parse URL e remove query parameters
        from urllib.parse import urlparse
        parsed = urlparse(url)
        path = parsed.path
        
        # Extrair extens√£o do arquivo
        ext = '.jpg'  # Default
        if '.' in path:
            # Pegar a parte do path antes de qualquer query param
            clean_path = path.split('?')[0]
            if '.' in clean_path:
                base_ext = clean_path.rsplit('.', 1)[-1].lower()
                # Validar extens√£o
                if base_ext in ['jpg', 'jpeg', 'png', 'webp', 'gif']:
                    ext = f'.{base_ext}'
        
        # Gerar filename limpo: instagram_username_01.jpg
        filename = f"instagram_{username}_{index:02d}{ext}"
        return sanitize_filename(filename, max_length=100)
    except Exception as e:
        logger.warning(f"Failed to clean filename from {url}: {e}")
        return f"instagram_image_{index:02d}.jpg"


def transcribe_instagram_carousel(url: str, prompt: Optional[str]) -> list[dict]:
    """Baixa imagens do carrossel e transcreve cada uma em paralelo para maior velocidade."""
    t0 = perf_counter()
    
    # Extract username from URL for clean filenames
    username = extract_username_from_instagram_url(url)
    logger.info(f"üì∏ Extracting carousel from @{username}")
    
    # First, get direct URLs (for frontend display)
    direct_urls = execute_gallery_dl_urls(url)
    logger.info(f"üì∏ Found {len(direct_urls)} direct URLs")
    
    # Then download and transcribe
    result = execute_gallery_dl(url)
    t1 = perf_counter()
    logger.info(f"‚è±Ô∏è gallery-dl download: {(t1 - t0) * 1000:.0f}ms")

    raw_download_dir = result.get("download_dir")
    download_dir = Path(raw_download_dir) if raw_download_dir else None
    files = result.get("files", [])
    if not files:
        raise HTTPException(status_code=404, detail="Nenhuma imagem encontrada")

    # Prepare tasks for parallel processing
    tasks = []
    for idx, info in enumerate(files, start=1):
        file_path = Path(info.get("path", ""))
        # Get corresponding direct URL (if available)
        direct_url = direct_urls[idx - 1] if idx <= len(direct_urls) else None
        
        if not file_path.exists():
            continue
        if file_path.stat().st_size > 25 * 1024 * 1024:
            tasks.append((idx, file_path, direct_url, None, "Arquivo maior que 25MB, ignorado"))
            continue

        mime, _ = mimetypes.guess_type(file_path.name)
        mime = mime or "image/png"

        # Skip video files - only transcribe images
        if mime.startswith("video/"):
            tasks.append((idx, file_path, direct_url, mime, "video"))
        elif mime.startswith("image/"):
            tasks.append((idx, file_path, direct_url, mime, "image"))
        else:
            tasks.append((idx, file_path, direct_url, mime, "unknown"))

    items = []
    try:
        # Process images in parallel using ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=5) as executor:
            def process_image(task_data):
                idx, file_path, direct_url, mime, task_type = task_data
                t_start = perf_counter()

                # Generate clean filename for download
                clean_filename = clean_instagram_filename(direct_url, username, idx)
                
                if task_type == "video":
                    result = {
                        "index": idx,
                        "file": file_path.name,
                        "url": direct_url,
                        "filename": clean_filename,  # Clean filename for download
                        "is_video": True,
                        "text": ""
                    }
                    logger.info(f"‚è© Skipped video {file_path.name}")
                    return result
                elif task_type == "image" or task_type == "unknown":
                    text = transcribe_image_bytes(file_path.read_bytes(), mime_type=mime, prompt=prompt)
                    t_end = perf_counter()
                    logger.info(f"‚è±Ô∏è Transcribed {file_path.name}: {(t_end - t_start) * 1000:.0f}ms")
                    return {
                        "index": idx,
                        "file": file_path.name,
                        "url": direct_url,
                        "filename": clean_filename,  # Clean filename for download
                        "is_video": False,
                        "text": text
                    }
                else:
                    clean_filename = clean_instagram_filename(direct_url, username, idx)
                    return {
                        "index": idx,
                        "file": file_path.name,
                        "url": direct_url,
                        "filename": clean_filename,  # Clean filename for download
                        "error": task_type
                    }

            t2 = perf_counter()
            # Execute all transcriptions in parallel
            items = list(executor.map(process_image, tasks))
            t3 = perf_counter()
            logger.info(f"‚è±Ô∏è Parallel transcription total: {(t3 - t2) * 1000:.0f}ms for {len(tasks)} items")
            logger.info(f"‚è±Ô∏è Total carousel processing: {(t3 - t0) * 1000:.0f}ms")
    finally:
        if download_dir and download_dir.exists():
            shutil.rmtree(download_dir, ignore_errors=True)

    if not items:
        raise HTTPException(status_code=404, detail="Nenhum item processado")
    return items

# Criar diret√≥rios essenciais
COOKIES_DIR.mkdir(parents=True, exist_ok=True)
DOWNLOADS_DIR.mkdir(parents=True, exist_ok=True)

# FastAPI app
app = FastAPI(
    title="N8N Download Bridge API",
    description="API para download de v√≠deos e imagens via yt-dlp e gallery-dl",
    version="2.0.0"
)

# GZip compression for API responses (not for video/image files)
app.add_middleware(GZipMiddleware, minimum_size=1000)

# CORS para chamadas de browser (preflight/OPTIONS)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["X-File-Size", "X-Tool-Used", "X-Format", "X-Total-Files", "X-Processing-Time-Ms"],
)

# Security
api_key_header = APIKeyHeader(name="X-API-Key", auto_error=True)

# Frontend est√°tico (UI) - prioriza build do Vite (frontend/dist)
if FRONTEND_BUILD_DIR.exists():
    app.mount("/ui", StaticFiles(directory=FRONTEND_BUILD_DIR, html=True), name="ui")
elif FRONTEND_DIR.exists():
    app.mount("/ui", StaticFiles(directory=FRONTEND_DIR, html=True), name="ui")
else:
    logger.warning("Frontend directory n√£o encontrado; rota /ui desabilitada.")


# Models
class DownloadRequest(BaseModel):
    url: HttpUrl
    tool: Literal["yt-dlp", "gallery-dl"]
    format: Optional[Literal["mp4", "webm", "best"]] = "mp4"
    quality: Optional[str] = "best"


class DownloadResponse(BaseModel):
    success: bool
    message: str
    file_path: Optional[str] = None
    file_size: Optional[str] = None
    direct_url: Optional[str] = None
    thumbnail_url: Optional[str] = None
    tool_used: str
    format: Optional[str] = None
    direct_urls: Optional[list[str]] = None  # para respostas que trazem v√°rias URLs


class AudioDownloadRequest(BaseModel):
    url: HttpUrl
    format: Optional[Literal["mp3", "m4a", "wav"]] = "mp3"
    language: Optional[str] = None


class InstagramTranscribeRequest(BaseModel):
    url: HttpUrl
    prompt: Optional[str] = None  # ignorado; usamos prompt padr√£o


# Dependency para validar API Key
async def validate_api_key(api_key: str = Security(api_key_header)):
    if api_key != API_KEY:
        logger.warning(f"Tentativa de acesso com API Key inv√°lida: {api_key[:10]}...")
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="API Key inv√°lida"
        )
    return api_key


def get_file_size(file_path: Path) -> str:
    """Retorna o tamanho do arquivo em formato leg√≠vel"""
    size = file_path.stat().st_size
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024.0:
            return f"{size:.1f}{unit}"
        size /= 1024.0
    return f"{size:.1f}TB"


def cleanup_path(path: Path):
    """Remove arquivo ou diret√≥rio de forma segura (para BackgroundTask)"""
    try:
        if path.exists():
            if path.is_dir():
                shutil.rmtree(path, ignore_errors=True)
                logger.info(f"Cleaned up directory: {path}")
            else:
                path.unlink(missing_ok=True)
                logger.info(f"Cleaned up file: {path}")
    except Exception as e:
        logger.warning(f"Failed to cleanup {path}: {e}")


def execute_ytdlp(url: str, download_file: bool = True, output_format: str = "mp4") -> dict:
    """Executa yt-dlp e retorna informa√ß√µes do download"""

    # Para TikTok, tentar tikwm.com primeiro, mas fallback para yt-dlp se falhar
    if "tiktok" in url.lower() and download_file:
        try:
            logger.info("TikTok detectado - tentando API tikwm.com")
            return download_tiktok_via_tikwm(url, DOWNLOADS_DIR)
        except Exception as e:
            logger.warning(f"tikwm.com falhou: {e}. Usando yt-dlp como fallback.")

    t0 = perf_counter()
    platform = detectPlatform(url)
    
    # Use meaningful filenames based on platform
    if download_file:
        if platform == "youtube":
            output_template = str(DOWNLOADS_DIR / "%(title)s.%(ext)s")
        else:
            output_template = str(DOWNLOADS_DIR / "%(uploader)s_%(id)s.%(ext)s")
    else:
        # For URL extraction, timestamp is fine
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_template = str(DOWNLOADS_DIR / f"video_{timestamp}.%(ext)s")

    # Comando base
    cmd = [choose_yt_dlp_binary_for_url(url)]

    # Adicionar cookies se existir
    cookies_args = get_cookies_args(url)
    cmd.extend(cookies_args)
    t1 = perf_counter()
    # Adicionar impersonation se necess√°rio
    cmd.extend(get_impersonate_args(url))
    lower_url = url.lower()
    is_tiktok = "tiktok.com" in lower_url
    is_youtube = "youtube.com" in lower_url or "youtu.be" in lower_url

    if download_file:
        # Configurar formato de acordo com a prefer√™ncia
        if output_format == "mp4":
            if is_tiktok:
                # Preferir stream progressivo (sem merge) para acelerar
                cmd.extend([
                    "-f",
                    "bv*[ext=mp4][protocol!*=dash][protocol!*=m3u8][acodec!=none]/"
                    "b[ext=mp4]/best"
                ])
            elif is_youtube:
                # YouTube: MAXIMUM SPEED optimization while keeping max quality
                # Use pre-merged formats when available (avoids ffmpeg merge time)
                cmd.extend([
                    '-f', 
                    # Priority 1: Pre-merged high quality (no merge needed = faster)
                    'best[height>=1080][ext=mp4]/'
                    # Priority 2: Best video + best audio (needs merge but max quality)
                    'bv*[height>=1080][ext=mp4]+ba[ext=m4a]/'
                    'bv*[height>=1080]+ba/'
                    # Priority 3: Any best available
                    'bv+ba/b',
                    '--extractor-args', 'youtube:player_client=ios,web',  # Try iOS client first (faster)
                    '--concurrent-fragments', '16',  # Download 16 fragments simultaneously
                    '--buffer-size', '32K',  # Larger buffer
                    '--http-chunk-size', '10M',  # Large chunks
                    '--retries', '3',  # Quick retry
                    '--fragment-retries', '3',
                    '--no-check-certificate',  # Skip cert verification (faster)
                ])
                # Use aria2c for multi-threaded downloads (MUCH faster)
                if shutil.which("aria2c"):
                    cmd.extend([
                        '--external-downloader', 'aria2c',
                        '--external-downloader-args', 
                        'aria2c:-x 16 -s 16 -k 2M --min-split-size=1M --max-connection-per-server=16 --enable-http-pipelining=true',
                    ])
                    logger.info("‚ö° YouTube: Using aria2c with 16 parallel connections for MAX SPEED")
                else:
                    # Even without aria2c, use concurrent fragments
                    logger.info("‚ö° YouTube: Using concurrent fragments (16) for faster download")
            else:
                # Preferir h264/aac para compatibilidade ampla (Safari/iOS)
                cmd.extend([
                    '-f',
                    'bv*[vcodec^=avc1][ext=mp4]+ba[ext=m4a]/'
                    'bv*[vcodec^=h264][ext=mp4]+ba[ext=m4a]/'
                    'b[ext=mp4]',
                    '--merge-output-format', 'mp4',
                    '--remux-video', 'mp4'
                ])
        elif output_format == "webm":
            cmd.extend(['-f', 'bestvideo[ext=webm]+bestaudio[ext=webm]/best[ext=webm]/best'])
        else:  # best
            cmd.extend(['-f', 'best'])

        if is_tiktok:
            cmd.extend(["--concurrent-fragments", "8"])
        cmd.extend([
            '-o', output_template,
            '--no-playlist',
            '--restrict-filenames',  # ASCII-only filenames
            '--trim-filenames', '200',  # Limit filename length
            '--progress',
            '--newline',
            '--no-warnings'
        ])
    else:
        # Modo URL direta: retorna melhor URL dispon√≠vel (pode ser m3u8/MP4)
        if is_tiktok:
            cmd.extend([
                '--skip-download',
                '--no-warnings',
                '--print', 'thumbnail',
                '--print', 'url',
                '--concurrent-fragments', '8',
            ])
        else:
            cmd.extend([
                '--skip-download',
                '--print', 'thumbnail',
                '--print', 'url',
            ])

    cmd.append(str(url))

    logger.info(f"Executando: {' '.join(cmd)}")

    t2 = perf_counter()
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300,
            check=True
        )
        t3 = perf_counter()

        if download_file:
            # Procurar arquivo baixado (search by most recent since filename is dynamic)
            downloaded_files = sorted(
                DOWNLOADS_DIR.glob("*.mp4"),
                key=lambda p: p.stat().st_mtime,
                reverse=True
            )
            if downloaded_files:
                file_path = downloaded_files[0]
                t4 = perf_counter()
                logger.info(
                    "yt-dlp timing cookies=%.1fms prep=%.1fms run=%.1fms post=%.1fms",
                    (t1 - t0) * 1000,  # resolu√ß√£o de cookies
                    (t2 - t1) * 1000,  # montagem de comando
                    (t3 - t2) * 1000,  # execu√ß√£o yt-dlp
                    (t4 - t3) * 1000,  # p√≥s-processamento
                )
                return {
                    "success": True,
                    "file_path": str(file_path),
                    "file_size": get_file_size(file_path),
                    "output": result.stdout,
                    "format": file_path.suffix[1:]  # Remove o ponto da extens√£o
                }
            else:
                raise Exception("Arquivo n√£o encontrado ap√≥s download")
        else:
            # Retornar URL direta + thumbnail (quando dispon√≠vel)
            lines = [line.strip() for line in result.stdout.splitlines() if line.strip()]
            thumbnail_url = None
            direct_urls: list[str] = []
            if not lines:
                raise Exception("Nenhuma URL retornada pelo yt-dlp")

            if len(lines) >= 2:
                thumb = lines[0]
                if thumb.lower() not in ("na", "none"):
                    thumbnail_url = thumb
                direct_urls = [line for line in lines[1:] if line.lower() not in ("na", "none")]
            else:
                if lines[0].lower() not in ("na", "none"):
                    direct_urls = [lines[0]]

            direct_url = direct_urls[0] if direct_urls else None
            t4 = perf_counter()
            logger.info(
                "yt-dlp timing cookies=%.1fms prep=%.1fms run=%.1fms post=%.1fms",
                (t1 - t0) * 1000,  # resolu√ß√£o de cookies
                (t2 - t1) * 1000,  # montagem de comando
                (t3 - t2) * 1000,  # execu√ß√£o yt-dlp
                (t4 - t3) * 1000,  # p√≥s-processamento
            )
            return {
                "success": True,
                "direct_url": direct_url,
                "direct_urls": direct_urls,
                "thumbnail_url": thumbnail_url,
                "output": result.stdout
            }

    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=408, detail="Download timeout (5 minutos)")
    except subprocess.CalledProcessError as e:
        logger.error(f"Erro no yt-dlp: {e.stderr}")
        error_msg = e.stderr or str(e)

        # Provide more user-friendly error messages
        if "Unable to extract" in error_msg or "Unable to download" in error_msg or "IP address is blocked" in error_msg or "Video not available" in error_msg:
            if "instagram" in url.lower():
                raise HTTPException(
                    status_code=503,
                    detail="Instagram bloqueou o download. Verifique se a conta √© privada ou tente novamente mais tarde."
                )
            elif "youtube" in url.lower():
                raise HTTPException(
                    status_code=503,
                    detail="YouTube bloqueou o download. Tente novamente em alguns minutos."
                )
            else:
                raise HTTPException(
                    status_code=503,
                    detail="Falha ao extrair v√≠deo. O site pode ter mudado ou bloqueado o acesso."
                )
        elif "Private video" in error_msg or "private" in error_msg.lower():
            raise HTTPException(
                status_code=403,
                detail="V√≠deo privado. N√£o √© poss√≠vel baixar v√≠deos privados."
            )
        elif "not available" in error_msg.lower():
            raise HTTPException(
                status_code=404,
                detail="V√≠deo n√£o dispon√≠vel ou foi removido."
            )
        else:
            raise HTTPException(status_code=500, detail=f"Erro no download: {error_msg[:200]}")
    except Exception as e:
        logger.error(f"Erro inesperado: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def stream_ytdlp(url: str, output_format: str = "mp4") -> dict:
    """
    Executa yt-dlp mandando sa√≠da para stdout (sem gravar em disco).
    Retorna bytes do arquivo e metadados b√°sicos.
    """
    t0 = perf_counter()

    cmd = [choose_yt_dlp_binary_for_url(url)]
    cmd.extend(get_cookies_args(url))
    cmd.extend(get_impersonate_args(url))
    lower_url = url.lower()
    is_tiktok = "tiktok.com" in lower_url

    # Para TikTok, n√£o force formato; deixe yt-dlp escolher progressivo quando poss√≠vel
    if is_tiktok:
        fmt = (
            "bv*[ext=mp4][protocol!*=dash][protocol!*=m3u8][acodec!=none]/"
            "b[ext=mp4]/best"
        )
    elif output_format == "mp4":
        fmt = (
            "best[ext=mp4][vcodec!=none][acodec!=none][protocol!*=m3u8]/"
            "best[ext=mp4][vcodec!=none][acodec!=none]/"
            "best[ext=mp4][protocol!*=m3u8]/"
            "best[protocol!*=m3u8]"
        )
    elif output_format == "webm":
        fmt = (
            "best[ext=webm][vcodec!=none][acodec!=none][protocol!*=m3u8]/"
            "best[ext=webm][vcodec!=none][acodec!=none]/"
            "best[ext=webm][protocol!*=m3u8]/"
            "best[protocol!*=m3u8]"
        )
    else:
        fmt = "best"

    cmd.extend([
        "-f", fmt,
        "-o", "-",
        "--no-playlist",
        "--quiet",
        "--no-warnings",
        "--no-progress",
    ])

    if is_tiktok:
        cmd.extend(["--concurrent-fragments", "8"])

    cmd.append(str(url))
    logger.info(f"Streaming yt-dlp: {' '.join(cmd)}")

    try:
        result = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=True,
            timeout=600
        )
        data = result.stdout or b""
        if not data:
            raise HTTPException(status_code=500, detail="The downloaded stream is empty")
        # Verifica√ß√£o r√°pida de header MP4/WebM para evitar enviar lixo
        if output_format == "mp4" and b"ftyp" not in data[:128]:
            raise HTTPException(status_code=500, detail="Stream n√£o √© MP4 v√°lido (faltando ftyp); tente /download/binary")
        if output_format == "webm" and not (data.startswith(b"\x1aE\xdf\xa3") or b"webm" in data[:128].lower()):
            raise HTTPException(status_code=500, detail="Stream n√£o √© WebM v√°lido; tente /download/binary")
        mime = "video/mp4" if output_format == "mp4" else "video/webm"
        t1 = perf_counter()
        logger.info("yt-dlp stream timing total=%.1fms", (t1 - t0) * 1000)
        return {
            "data": data,
            "mime": mime,
            "size": len(data),
            "format": output_format
        }
    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=408, detail="Streaming timeout (10 minutos)")
    except subprocess.CalledProcessError as e:
        logger.error(f"Erro no yt-dlp (stream): {e.stderr}")
        raise HTTPException(status_code=500, detail=f"Erro no yt-dlp: {e.stderr.decode(errors='ignore')}")
    except Exception as e:
        logger.error(f"Erro inesperado (stream): {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def stream_ytdlp_merge(url: str, output_format: str = "mp4") -> dict:
    """
    Baixa melhor qualidade (v√≠deo+√°udio separados) e mescla em arquivo tempor√°rio.
    Remove o arquivo ap√≥s o streaming (via BackgroundTask).
    """
    t0 = perf_counter()

    # caminho tempor√°rio controlado
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=f".{output_format}")
    tmp_path = Path(tmp.name)
    tmp.close()

    cmd = [choose_yt_dlp_binary_for_url(url)]
    cmd.extend(get_cookies_args(url))
    cmd.extend(get_impersonate_args(url))
    cmd.extend([
        "-f", "bv*+ba/bestvideo+bestaudio/best",
        "--merge-output-format", output_format,
        "-o", str(tmp_path.with_suffix(".%(ext)s")),
        "--no-playlist",
        "--newline",
    ])
    cmd.append(str(url))

    logger.info(f"Streaming (merge) yt-dlp: {' '.join(cmd)}")
    try:
        result = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=True,
            timeout=900
        )
        # localizar arquivo gerado (pode ter extens√£o real diferente)
        generated = list(tmp_path.parent.glob(f"{tmp_path.stem}.*"))
        if not generated:
            raise HTTPException(status_code=500, detail="Arquivo mesclado n√£o encontrado")
        file_path = generated[0]
        mime = "video/mp4" if output_format == "mp4" else "video/webm"
        size = file_path.stat().st_size
        if size == 0:
            raise HTTPException(status_code=500, detail="Arquivo mesclado est√° vazio")
        t1 = perf_counter()
        logger.info("yt-dlp merge timing total=%.1fms", (t1 - t0) * 1000)
        return {
            "file_path": file_path,
            "mime": mime,
            "size": size,
            "format": output_format
        }
    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=408, detail="Merge timeout (15 minutos)")
    except subprocess.CalledProcessError as e:
        logger.error(f"Erro no yt-dlp (merge stream): {e.stderr}")
        raise HTTPException(status_code=500, detail=f"Erro no yt-dlp: {e.stderr.decode(errors='ignore')}")
    except Exception as e:
        logger.error(f"Erro inesperado (merge stream): {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def execute_gallery_dl(url: str) -> dict:
    """Executa gallery-dl e retorna informa√ß√µes do download"""

    t0 = perf_counter()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = DOWNLOADS_DIR / f"gallery_{timestamp}"
    output_dir.mkdir(exist_ok=True)

    cmd = [get_gallery_dl_binary()]

    # Adicionar cookies se existir
    cookies_args = get_cookies_args(url)
    cmd.extend(cookies_args)
    t1 = perf_counter()

    cmd.extend([
        "-d", str(output_dir),
        "--write-metadata",
        str(url)
    ])

    logger.info(f"Executando: {' '.join(cmd)}")

    t2 = perf_counter()
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300,
            check=True
        )
        t3 = perf_counter()

        # Procurar arquivos baixados com seus metadados
        file_with_metadata = []
        for f in output_dir.rglob("*"):
            if not f.is_file() or f.name.endswith('.json'):
                continue

            # Procurar arquivo de metadata correspondente
            metadata_file = f.with_suffix(f.suffix + '.json')
            num = None
            if metadata_file.exists():
                try:
                    with open(metadata_file, 'r') as mf:
                        meta = json.load(mf)
                        # Instagram usa 'num' para indicar a posi√ß√£o no carrossel
                        num = meta.get('num', meta.get('count', meta.get('position')))
                except Exception as e:
                    logger.warning(f"Erro ao ler metadata de {f.name}: {e}")

            file_with_metadata.append((f, num))

        # Ordenar: primeiro por 'num' (se dispon√≠vel), depois por nome natural
        def sort_key(item):
            path, num = item
            if num is not None:
                return (0, num, path.name)
            # Natural sort para arquivos sem metadata
            parts = re.split(r'(\d+)', path.name)
            natural_parts = [int(part) if part.isdigit() else part for part in parts]
            return (1, 0, natural_parts)

        file_with_metadata.sort(key=sort_key)
        downloaded_files = [path for path, _ in file_with_metadata]

        if downloaded_files:
            files_info = [
                {
                    "path": str(f),
                    "size": get_file_size(f),
                    "name": f.name
                }
                for f in downloaded_files
            ]

            t4 = perf_counter()
            logger.info(
                "gallery-dl timing cookies=%.1fms prep=%.1fms run=%.1fms post=%.1fms",
                (t1 - t0) * 1000,  # resolu√ß√£o de cookies
                (t2 - t1) * 1000,  # montagem de comando
                (t3 - t2) * 1000,  # execu√ß√£o gallery-dl
                (t4 - t3) * 1000,  # p√≥s-processamento
            )
            return {
                "success": True,
                "files": files_info,
                "output": result.stdout,
                "download_dir": str(output_dir)
            }
        else:
            raise Exception("Nenhum arquivo encontrado ap√≥s download")

    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=408, detail="Download timeout (5 minutos)")
    except subprocess.CalledProcessError as e:
        logger.error(f"Erro no gallery-dl: {e.stderr}")
        raise HTTPException(status_code=500, detail=f"Erro no gallery-dl: {e.stderr}")
    except Exception as e:
        logger.error(f"Erro inesperado: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def execute_gallery_dl_urls(url: str) -> list[str]:
    """Retorna URLs diretas usando gallery-dl sem baixar arquivos"""
    cmd = [get_gallery_dl_binary(), "-g"]
    cmd.extend(get_cookies_args(url))
    cmd.append(str(url))

    logger.info(f"Executando (URLs apenas): {' '.join(cmd)}")
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=180,
            check=True
        )
        urls: list[str] = []

        def _looks_like_media(u: str) -> bool:
            try:
                parsed = urlparse(u)
                host = parsed.netloc.lower()
                path = parsed.path.lower()
            except Exception:
                return True

            ext = Path(path).suffix.lstrip(".").lower()
            blocked_ext = {"json", "txt", "html", "xml"}
            allowed_ext = {
                "mp4", "webm", "mov", "m4v", "mp3", "m4a", "aac",
                "jpg", "jpeg", "png", "gif", "webp", "m3u8", "mpd"
            }

            if ext in blocked_ext:
                return False
            if ext in allowed_ext:
                return True

            # Instagram: ignore URLs que n√£o s√£o CDN de m√≠dia
            if "instagram.com" in host and not any(cdn in host for cdn in ["cdninstagram.com", "fbcdn.net", "fna.fbcdn.net"]):
                return False

            # TikTok: se n√£o tem extens√£o e n√£o parece arquivo, provavelmente √© p√°gina HTML
            if "tiktok.com" in host and not ext:
                return False

            return True

        for raw_line in result.stdout.splitlines():
            line = raw_line.strip()
            if not line:
                continue

            # Skip ytdl: prefixed lines (not direct URLs)
            if line.startswith("ytdl:"):
                continue

            # gallery-dl √†s vezes retorna linhas com prefixo "| " ou texto extra;
            # extrai a primeira URL http(s) v√°lida para evitar gerar paths inv√°lidos no frontend
            if line.startswith("|"):
                line = line.lstrip("|").strip()

            match = re.search(r"https?://\S+", line)
            if not match:
                continue

            candidate = match.group(0).rstrip("|,\"'")
            if candidate.startswith(("http://", "https://")) and candidate not in urls and _looks_like_media(candidate):
                urls.append(candidate)

        if not urls:
            raise HTTPException(status_code=404, detail="Nenhuma URL retornada pelo gallery-dl")
        return urls
    except subprocess.TimeoutExpired:
        raise HTTPException(status_code=408, detail="Timeout ao obter URLs (3 minutos)")
    except subprocess.CalledProcessError as e:
        logger.error(f"Erro no gallery-dl (URLs): {e.stderr}")
        raise HTTPException(status_code=500, detail=f"Erro no gallery-dl: {e.stderr}")
    except Exception as e:
        logger.error(f"Erro inesperado (URLs): {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def zip_directory(source_dir: Path) -> Path:
    """Compacta um diret√≥rio em ZIP e retorna o caminho do arquivo"""
    zip_name = DOWNLOADS_DIR / f"{source_dir.name}.zip"
    try:
        if zip_name.exists():
            zip_name.unlink()
        shutil.make_archive(zip_name.with_suffix(''), 'zip', root_dir=source_dir)
        return zip_name
    except Exception as e:
        logger.error(f"Erro ao zipar diret√≥rio {source_dir}: {e}")
        raise HTTPException(status_code=500, detail="Falha ao gerar ZIP")


# Endpoints
@app.get("/")
async def root():
    # Redireciona para a UI quando ela estiver presente
    if FRONTEND_DIR.exists():
        return RedirectResponse(url="/ui", status_code=307)
    return {
        "name": "N8N Download Bridge API",
        "version": "2.0.0",
        "status": "online",
        "endpoints": {
            "/health": "Health check",
            "/download": "Download e retorna JSON com info do arquivo",
            "/download/binary": "Download e retorna arquivo bin√°rio direto",
            "/download/url": "Retorna URL direta sem fazer download"
        }
    }


@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "yt-dlp": subprocess.run(["yt-dlp", "--version"], capture_output=True, text=True).stdout.strip(),
        "gallery-dl": subprocess.run(["gallery-dl", "--version"], capture_output=True, text=True).stdout.strip(),
        "cookies_file_exists": any(path.exists() for path in COOKIES_CANDIDATES + ALT_COOKIES_FILES),
        "downloads_dir": str(DOWNLOADS_DIR),
        "cookies_dir": str(COOKIES_DIR)
    }


@app.get("/youtube/formats")
async def get_youtube_formats(
    url: str = Query(..., description="YouTube video URL"),
    api_key: str = Security(validate_api_key)
):
    """
    Get all available formats for a YouTube video without downloading.
    Returns video and audio quality options with file sizes.
    """
    import json
    logger.info(f"üìã Fetching formats for: {url}")
    
    # #region agent log
    try:
        with open('/Users/miguelcrasto/Downloads/social-media-transcription/.cursor/debug.log', 'a') as f:
            f.write(json.dumps({"location":"main.py:1824","message":"get_youtube_formats entry","data":{"url":url[:100]},"timestamp":int(__import__('time').time()*1000),"sessionId":"debug-session","runId":"run1","hypothesisId":"D,E"})+"\n")
    except: pass
    # #endregion
    
    try:
        cmd = [choose_yt_dlp_binary_for_url(url)]
        cmd.extend(get_cookies_args(url))
        cmd.extend([
            '-F',  # List all formats
            '--no-warnings',
            '--no-playlist',  # Don't process playlists, only the single video
            '--playlist-end', '1',  # Safety: only process first item if playlist detected
            url
        ])
        
        # #region agent log
        try:
            with open('/Users/miguelcrasto/Downloads/social-media-transcription/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"location":"main.py:1844","message":"Before subprocess.run","data":{"cmd":' '.join(cmd[:6])+"..."},"timestamp":int(__import__('time').time()*1000),"sessionId":"debug-session","runId":"run2","hypothesisId":"E"})+"\n")
        except: pass
        # #endregion
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=30,  # Reduced to 30 seconds since we're not processing playlists
            check=True
        )
        
        # #region agent log
        try:
            with open('/Users/miguelcrasto/Downloads/social-media-transcription/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"location":"main.py:1852","message":"After subprocess.run","data":{"returncode":result.returncode,"stdoutLength":len(result.stdout),"stderrLength":len(result.stderr)},"timestamp":int(__import__('time').time()*1000),"sessionId":"debug-session","runId":"run1","hypothesisId":"E"})+"\n")
        except: pass
        # #endregion
        
        # Parse yt-dlp format output
        formats = []
        lines = result.stdout.split('\n')
        
        for line in lines:
            # Skip header and empty lines
            if not line.strip() or 'format code' in line.lower() or line.startswith('-'):
                continue
                
            # Parse format line
            parts = line.split()
            if len(parts) < 3:
                continue
                
            format_id = parts[0]
            ext = parts[1]
            
            # Extract resolution and filesize
            resolution = 'audio only' if 'audio only' in line else ''
            filesize = ''
            note = ''
            
            for i, part in enumerate(parts):
                if 'x' in part and part.replace('x', '').isdigit():
                    resolution = part
                elif 'MiB' in part or 'KiB' in part or 'GiB' in part:
                    # Clean up the filesize
                    if i > 0:
                        size_num = parts[i-1].lstrip('|~‚âà')
                        if size_num.replace('.', '').isdigit():
                            filesize = f"~{size_num} {part}"
                        else:
                            filesize = f"~{part}"
                    else:
                        filesize = f"~{part}"
                elif part.endswith('p') and part[:-1].isdigit():
                    resolution = part
            
            # Quality labels
            if 'audio only' in line:
                note = '√Åudio'
            elif '2160' in line or '4k' in line.lower():
                note = '4K Ultra HD'
            elif '1440' in line:
                note = '2K Quad HD'
            elif '1080' in line:
                note = 'Full HD 1080p'
            elif '720' in line:
                note = 'HD 720p'
            elif '480' in line:
                note = 'SD 480p'
            elif '360' in line:
                note = 'SD 360p'
            
            if note:  # Only include formats we can label
                formats.append({
                    'format_id': format_id,
                    'ext': ext,
                    'resolution': resolution,
                    'filesize': filesize,
                    'note': note
                })
        
        logger.info(f"‚úÖ Found {len(formats)} formats")
        
        # #region agent log
        try:
            with open('/Users/miguelcrasto/Downloads/social-media-transcription/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"location":"main.py:1915","message":"Before return response","data":{"formatsCount":len(formats)},"timestamp":int(__import__('time').time()*1000),"sessionId":"debug-session","runId":"run1","hypothesisId":"G"})+"\n")
        except: pass
        # #endregion
        
        return {
            'success': True,
            'formats': formats
        }
        
    except subprocess.TimeoutExpired as e:
        # #region agent log
        try:
            with open('/Users/miguelcrasto/Downloads/social-media-transcription/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"location":"main.py:1922","message":"TimeoutExpired","data":{"error":str(e)},"timestamp":int(__import__('time').time()*1000),"sessionId":"debug-session","runId":"run1","hypothesisId":"E"})+"\n")
        except: pass
        # #endregion
        raise HTTPException(status_code=408, detail="Timeout ao buscar formatos")
    except subprocess.CalledProcessError as e:
        # #region agent log
        try:
            with open('/Users/miguelcrasto/Downloads/social-media-transcription/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"location":"main.py:1927","message":"CalledProcessError","data":{"returncode":e.returncode,"stderr":e.stderr[:200] if e.stderr else None},"timestamp":int(__import__('time').time()*1000),"sessionId":"debug-session","runId":"run1","hypothesisId":"E"})+"\n")
        except: pass
        # #endregion
        logger.error(f"Erro ao buscar formatos: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro ao buscar formatos: {str(e)}")
    except Exception as e:
        # #region agent log
        try:
            with open('/Users/miguelcrasto/Downloads/social-media-transcription/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({"location":"main.py:1932","message":"General Exception","data":{"errorType":type(e).__name__,"errorMessage":str(e)[:200]},"timestamp":int(__import__('time').time()*1000),"sessionId":"debug-session","runId":"run1","hypothesisId":"A,E"})+"\n")
        except: pass
        # #endregion
        logger.error(f"Erro ao buscar formatos: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro ao buscar formatos: {str(e)}")


@app.post("/download", response_model=DownloadResponse)
async def download_json(
    request: DownloadRequest,
    api_key: str = Security(validate_api_key)
):
    """
    Faz download e retorna JSON com informa√ß√µes do arquivo.
    Ideal para: processos que precisam de metadados do arquivo.
    """
    logger.info(f"Download JSON request: {request.url} usando {request.tool}")

    try:
        if request.tool == "yt-dlp":
            result = execute_ytdlp(str(request.url), download_file=True, output_format=request.format)
            return DownloadResponse(
                success=True,
                message="Download conclu√≠do com sucesso",
                file_path=result.get("file_path"),
                file_size=result.get("file_size"),
                tool_used="yt-dlp",
                format=result.get("format")
            )
        else:
            result = execute_gallery_dl(str(request.url))
            first_file = result["files"][0] if result["files"] else {}
            return DownloadResponse(
                success=True,
                message=f"Download conclu√≠do: {len(result['files'])} arquivo(s)",
                file_path=first_file.get("path"),
                file_size=first_file.get("size"),
                tool_used="gallery-dl"
            )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro no download: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/download/binary")
async def download_binary(
    url: str = Query(..., description="URL do v√≠deo/imagem"),
    format: Literal["mp4", "webm", "best"] = Query(default="mp4", description="Formato do v√≠deo"),
    quality: str = Query(default="max", description="Qualidade do v√≠deo (max, 1080, 720, 480)"),
    api_key: str = Security(validate_api_key)
):
    """
    Universal download endpoint for all platforms:
    - TikTok: Returns JSON with direct URL (tikwm.com API - fastest)
    - Instagram, YouTube, Twitter, Reddit, Pinterest, etc.: Uses Cobalt API (primary)
    - Fallback to yt-dlp if Cobalt fails
    """
    logger.info(f"üöÄ Binary download request: {url} formato={format} qualidade={quality}")
    
    t_start = perf_counter()
    platform = detectPlatform(url)
    
    try:
        # TikTok: Return direct URL via tikwm API (JSON response to avoid CORS issues)
        # Keep tikwm.com as it's fast and reliable for TikTok
        if platform == "tiktok":
            logger.info("üéµ TikTok detected - using tikwm API for direct URL")
            
            # Use tikwm to get video metadata
            api_url = f"https://www.tikwm.com/api/?url={url}"
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                "Connection": "keep-alive",
            }
            resp = requests.get(api_url, headers=headers, timeout=8, verify=False)
            resp.raise_for_status()
            data = resp.json()
            
            if data.get("code") != 0:
                # tikwm failed, try Cobalt as fallback
                logger.warning(f"tikwm failed: {data.get('msg', 'Unknown error')}, trying Cobalt...")
                return await _download_via_cobalt_with_fallback(url, platform, t_start, quality)
            
            video_data = data.get("data", {})
            
            # Try HD video first, then fallback to standard quality
            direct_url = video_data.get("hdplay") or video_data.get("play") or video_data.get("wmplay")
            
            if not direct_url:
                # No URL from tikwm, try Cobalt
                logger.warning("No video URL from tikwm, trying Cobalt...")
                return await _download_via_cobalt_with_fallback(url, platform, t_start, quality)
            
            # Extract username and video ID for filename (format: tiktok_username_videoid.mp4)
            author = video_data.get("author", {}).get("unique_id", "user")
            video_id = video_data.get("id", "video")
            filename = f"tiktok_{author}_{video_id}.mp4"
            
            t_end = perf_counter()
            total_ms = int((t_end - t_start) * 1000)
            logger.info(f"‚úÖ TikTok direct URL: {direct_url[:100]}...")
            logger.info(f"üìÅ Filename: {filename}")
            
            return Response(
                content=json.dumps({
                    "direct_url": direct_url,
                    "platform": platform,
                    "filename": filename
                }),
                media_type="application/json",
                headers={
                    "X-Direct-Download": "true",
                    "X-Platform": platform,
                    "X-Processing-Time-Ms": str(total_ms)
                }
            )
        
        # All other platforms: Use Cobalt API as primary with yt-dlp fallback
        # Supported: Instagram, YouTube, Twitter, Reddit, Pinterest, Twitch, Vimeo, SoundCloud, etc.
        else:
            if cobalt_config.COBALT_PRIMARY:
                logger.info(f"üåê {platform.title()} detected - using Cobalt API as primary")
                return await _download_via_cobalt_with_fallback(url, platform, t_start, quality)
            else:
                # Fallback to legacy methods when COBALT_PRIMARY is disabled
                return await _download_via_legacy_methods(url, platform, t_start, format)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro no binary stream: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


async def _download_via_cobalt_with_fallback(url: str, platform: str, t_start: float, quality: str = "max") -> Response:
    """
    Download via Cobalt API with fallback to yt-dlp/gallery-dl if Cobalt fails.
    Returns a Response with the downloaded content or JSON with direct_url.
    """
    try:
        logger.info(f"üì• Attempting Cobalt download for {platform}: {url}")
        result = download_via_cobalt(url, audio_only=False, quality=quality)
        
        content = result["blob"]
        filename = result["filename"]
        content_type = result.get("content_type", "video/mp4")
        
        t_end = perf_counter()
        total_ms = int((t_end - t_start) * 1000)
        size_mb = len(content) / (1024 * 1024)
        
        logger.info(f"‚úÖ Cobalt download successful for {platform}: {size_mb:.2f}MB in {total_ms}ms")
        
        return Response(
            content=content,
            media_type=content_type,
            headers={
                "Content-Disposition": f'attachment; filename="{filename}"',
                "X-Tool-Used": "cobalt-api",
                "X-Platform": platform,
                "X-Processing-Time-Ms": str(total_ms),
                "X-File-Size": str(len(content))
            }
        )
        
    except Exception as cobalt_error:
        logger.warning(f"‚ö†Ô∏è Cobalt failed for {platform}: {cobalt_error}")
        
        # Fallback to legacy methods
        if cobalt_config.ENABLE_YTDLP_FALLBACK:
            logger.info(f"üîÑ Falling back to legacy method for {platform}...")
            return await _download_via_legacy_methods(url, platform, t_start, "mp4")
        
        # No fallback, return error
        raise HTTPException(
            status_code=503,
            detail=f"Erro ao baixar via Cobalt: {str(cobalt_error)}. Tente novamente mais tarde."
        )


async def _download_via_legacy_methods(url: str, platform: str, t_start: float, format: str = "mp4") -> Response:
    """
    Download using legacy methods (yt-dlp, gallery-dl) when Cobalt is disabled or fails.
    """
    try:
        if platform == "instagram":
            logger.info("üì∏ Instagram - using gallery-dl for direct URL")
            try:
                urls = execute_gallery_dl_urls(url)
                
                if not urls:
                    raise HTTPException(status_code=404, detail="No media URLs found")
                
                direct_url = urls[0]
                username = extract_username_from_instagram_url(url)
                
                t_end = perf_counter()
                total_ms = int((t_end - t_start) * 1000)
                logger.info(f"‚úÖ Instagram direct URL extracted in {total_ms}ms")
                
                return Response(
                    content=json.dumps({
                        "direct_url": direct_url,
                        "platform": platform,
                        "username": username
                    }),
                    media_type="application/json",
                    headers={
                        "X-Direct-Download": "true",
                        "X-Platform": platform,
                        "X-Processing-Time-Ms": str(total_ms)
                    }
                )
            except Exception as e:
                logger.error(f"gallery-dl failed for Instagram: {e}")
                raise HTTPException(
                    status_code=503,
                    detail=f"Erro no gallery-dl: {str(e)}"
                )
        
        elif platform in ("youtube", "twitter", "reddit", "twitch", "vimeo", "dailymotion", "facebook", "other"):
            logger.info(f"üìπ {platform.title()} - using yt-dlp")
            result = execute_ytdlp_optimized(url, output_format=format)
            file_path = Path(result["file_path"])
            
            with open(file_path, "rb") as f:
                content = f.read()
            
            filename = file_path.name
            file_path.unlink(missing_ok=True)
            
            t_end = perf_counter()
            total_ms = int((t_end - t_start) * 1000)
            logger.info(f"‚úÖ {platform.title()} download completed in {total_ms}ms, size: {len(content)} bytes")
            
            return Response(
                content=content,
                media_type="video/mp4",
                headers={
                    "Content-Disposition": f'attachment; filename="{filename}"',
                    "X-Tool-Used": "yt-dlp",
                    "X-Platform": platform,
                    "X-Processing-Time-Ms": str(total_ms),
                    "X-File-Size": str(len(content))
                }
            )
        
        else:
            # Try yt-dlp for any unknown platform
            logger.info(f"üìπ Unknown platform ({platform}) - trying yt-dlp")
            result = execute_ytdlp_optimized(url, output_format=format)
            file_path = Path(result["file_path"])
            
            with open(file_path, "rb") as f:
                content = f.read()
            
            filename = file_path.name
            file_path.unlink(missing_ok=True)
            
            t_end = perf_counter()
            total_ms = int((t_end - t_start) * 1000)
            
            return Response(
                content=content,
                media_type="video/mp4",
                headers={
                    "Content-Disposition": f'attachment; filename="{filename}"',
                    "X-Tool-Used": "yt-dlp",
                    "X-Platform": platform,
                    "X-Processing-Time-Ms": str(total_ms),
                    "X-File-Size": str(len(content))
                }
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Legacy download failed for {platform}: {e}")
        raise HTTPException(status_code=500, detail=f"Erro no download: {str(e)}")




@app.options("/download/binary")
async def options_download_binary():
    """Permite preflight CORS do navegador para rota bin√°ria."""
    return Response(status_code=200)


@app.post("/download/url", response_model=DownloadResponse)
async def download_url(
    payload: DownloadRequest,
    api_key: str = Security(validate_api_key)
):
    """
    Retorna a URL direta do v√≠deo sem fazer download.
    Apenas funciona com yt-dlp.
    Ideal para: quando voc√™ quer apenas o link direto do v√≠deo.
    """
    if payload.tool != "yt-dlp":
        raise HTTPException(
            status_code=400,
            detail="Endpoint /download/url apenas suporta yt-dlp"
        )

    logger.info(f"Download URL request: {payload.url}")

    try:
        fmt = payload.format or "mp4"
        result = execute_ytdlp(str(payload.url), download_file=False, output_format=fmt)
        direct_url = result.get("direct_url")
        thumbnail_url = result.get("thumbnail_url")
        return DownloadResponse(
            success=True,
            message="URL obtida com sucesso",
            direct_url=direct_url,
            thumbnail_url=thumbnail_url,
            tool_used="yt-dlp",
            format=fmt
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao obter URL: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/download/gallery/zip")
async def download_gallery_zip(
    request: DownloadRequest,
    api_key: str = Security(validate_api_key)
):
    """Baixa todos os itens do carrossel/galeria, gera ZIP e retorna o arquivo"""
    if request.tool != "gallery-dl":
        raise HTTPException(status_code=400, detail="Use tool=gallery-dl para este endpoint")

    logger.info(f"Download Gallery ZIP: {request.url}")
    result = execute_gallery_dl(str(request.url))
    download_dir = Path(result["download_dir"])
    zip_path = zip_directory(download_dir)

    # Cleanup both zip and download directory after response
    async def cleanup_both():
        cleanup_path(zip_path)
        cleanup_path(download_dir)

    return FileResponse(
        path=zip_path,
        media_type="application/zip",
        filename=zip_path.name,
        headers={
            "X-File-Size": get_file_size(zip_path),
            "X-Tool-Used": "gallery-dl",
            "X-Total-Files": str(len(result.get("files", [])))
        },
        background=BackgroundTask(cleanup_both)
    )


@app.post("/download/gallery/urls", response_model=DownloadResponse)
async def download_gallery_urls(
    request: DownloadRequest,
    api_key: str = Security(validate_api_key)
):
    """Retorna URLs diretas das imagens do carrossel/galeria sem baixar nada"""
    if request.tool != "gallery-dl":
        raise HTTPException(status_code=400, detail="Use tool=gallery-dl para este endpoint")

    logger.info(f"Gallery URLs request: {request.url}")
    urls = execute_gallery_dl_urls(str(request.url))

    return DownloadResponse(
        success=True,
        message=f"{len(urls)} URL(s) obtidas com sucesso",
        tool_used="gallery-dl",
        direct_urls=urls
    )


@app.post("/convert/hls")
async def convert_hls_to_mp4(
    url: HttpUrl = Query(..., description="URL HLS (.m3u8)"),
    api_key: str = Security(validate_api_key)
):
    """
    Converte um link HLS (.m3u8) em MP4 usando yt-dlp+ffmpeg.
    Ideal para casos onde s√≥ h√° stream HLS dispon√≠vel.
    """
    logger.info(f"Convert HLS request: {url}")
    try:
        result = execute_ytdlp(str(url), download_file=True, output_format="mp4")
        file_path = Path(result["file_path"])
        return FileResponse(
            path=file_path,
            media_type="video/mp4",
            filename=file_path.name,
            headers={
                "X-File-Size": result["file_size"],
                "X-Tool-Used": "yt-dlp",
                "X-Format": result.get("format", "mp4")
            },
            background=BackgroundTask(cleanup_path, file_path)
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro na convers√£o HLS: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/download/stream")
async def download_stream(
    url: str = Query(..., description="URL do v√≠deo"),
    format: Literal["mp4", "webm", "best"] = Query(default="mp4"),
    allow_merge: bool = Query(default=False, description="Permite mesclar v√≠deo+√°udio em temp file para melhor qualidade"),
    api_key: str = Security(validate_api_key)
):
    """
    Faz download e retorna o arquivo via streaming (sem salvar no disco).
    Suporta apenas yt-dlp. Se allow_merge=true, baixa melhor qualidade (merge) e apaga o temp ap√≥s envio.
    """
    logger.info(f"Download Stream request: {url} fmt={format}")
    try:
        if allow_merge:
            merged = stream_ytdlp_merge(url, output_format=format if format != "best" else "mp4")
            headers = {
                "X-Tool-Used": "yt-dlp",
                "X-Format": merged.get("format", format),
                "X-File-Size": str(merged.get("size", 0)),
                "Content-Disposition": f'attachment; filename="video_merge.{merged.get("format", format)}"'
            }
            return StreamingResponse(
                merged["file_path"].open("rb"),
                media_type=merged["mime"],
                headers=headers,
                background=BackgroundTask(merged["file_path"].unlink, missing_ok=True)
            )
        else:
            result = stream_ytdlp(url, output_format=format)
            headers = {
                "X-Tool-Used": "yt-dlp",
                "X-Format": result.get("format", format),
                "X-File-Size": str(result.get("size", 0)),
                "Content-Disposition": f'attachment; filename="video_stream.{result.get("format", format)}"'
            }
            return StreamingResponse(
                BytesIO(result["data"]),
                media_type=result["mime"],
                headers=headers
            )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro no stream: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/audio/extract")
async def extract_audio(
    request: AudioDownloadRequest,
    api_key: str = Security(validate_api_key)
):
    """Baixa apenas o √°udio de um v√≠deo e retorna o arquivo."""
    audio_path = download_audio_from_url(str(request.url), request.format or "mp3")
    media_type = {
        "mp3": "audio/mpeg",
        "m4a": "audio/mp4",
        "wav": "audio/wav"
    }.get(audio_path.suffix.lstrip("."), "application/octet-stream")

    return FileResponse(
        path=audio_path,
        filename=audio_path.name,
        media_type=media_type,
        headers={
            "X-Format": audio_path.suffix.lstrip("."),
            "X-File-Size": get_file_size(audio_path),
            "X-Tool-Used": "yt-dlp"
        },
        background=BackgroundTask(audio_path.unlink, missing_ok=True)
    )


@app.post("/transcribe/video")
async def transcribe_video(
    request: AudioDownloadRequest,
    api_key: str = Security(validate_api_key)
):
    """
    Baixa o √°udio do v√≠deo via Cobalt e envia para o Whisper.
    Retorna o texto transcrito.
    """
    audio_path = None
    try:
        # Download audio using Cobalt
        logger.info(f"Downloading audio via Cobalt for transcription: {request.url}")
        result = download_via_cobalt(str(request.url), audio_only=True, quality="max")
        
        # Save to temporary file for Whisper
        audio_path = DOWNLOADS_DIR / result["filename"]
        with open(audio_path, "wb") as f:
            f.write(result["blob"])
        
        # Transcribe with Whisper
        transcript = transcribe_audio_file(audio_path, language=request.language)
        
        return {
            "success": True,
            "message": "Transcri√ß√£o conclu√≠da",
            "transcript": transcript,
            "format": audio_path.suffix.lstrip("."),
            "file_size": get_file_size(audio_path)
        }
    finally:
        if audio_path and audio_path.exists():
            audio_path.unlink(missing_ok=True)


@app.post("/transcribe/image")
async def transcribe_image(
    file: UploadFile = File(...),
    prompt: Optional[str] = Form(None),
    api_key: str = Security(validate_api_key)
):
    """Extrai texto de uma imagem usando modelo de vis√£o."""
    data = await file.read()
    if not data:
        raise HTTPException(status_code=400, detail="Imagem vazia")

    if len(data) > 25 * 1024 * 1024:
        raise HTTPException(status_code=413, detail="Arquivo de imagem muito grande")

    mime_type = file.content_type or "image/png"
    text = transcribe_image_bytes(data, mime_type=mime_type, prompt=prompt)

    return {
        "success": True,
        "message": "Texto extra√≠do com sucesso",
        "text": text,
        "mime": mime_type
    }


@app.post("/transcribe/instagram")
async def transcribe_instagram(
    request: InstagramTranscribeRequest,
    api_key: str = Security(validate_api_key)
):
    """
    Extrai texto das imagens de um post/carrossel do Instagram.
    Usa gallery-dl para baixar imagens e vision da OpenAI para transcri√ß√£o.
    MACROBENCHMARK: Tempo total do endpoint incluindo download + transcri√ß√£o paralela.
    """
    t_start = perf_counter()
    items = transcribe_instagram_carousel(str(request.url), request.prompt or DEFAULT_TRANSCRIBE_PROMPT)
    t_end = perf_counter()

    total_ms = int((t_end - t_start) * 1000)
    logger.info(f"üèÅ MACROBENCHMARK /transcribe/instagram: {total_ms}ms total")

    return Response(
        content=json.dumps({
            "success": True,
            "message": f"{len(items)} imagem(ns) processada(s)",
            "items": items,
            "performance": {
                "total_ms": total_ms,
                "avg_per_item_ms": total_ms // len(items) if items else 0
            }
        }),
        media_type="application/json",
        headers={
            "X-Processing-Time-Ms": str(total_ms),
            "X-Items-Processed": str(len(items))
        }
    )


if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    host = os.getenv("HOST", "0.0.0.0")
    uvicorn.run(app, host=host, port=port)
